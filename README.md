# An√°lise de Dados e Previs√£o de Estrat√©gia para a F√≥rmula 1 üèéÔ∏è

Este reposit√≥rio cont√©m um projeto completo de an√°lise de dados focado no automobilismo da F√≥rmula 1. Utilizando a API **FastF1**, foram coletados, processados e analisados dados de corrida do **Grande Pr√™mio da It√°lia (Monza)** entre os anos de **2018 e 2024**.

O objetivo final √© treinar um modelo de **Rede Neural Recorrente (LSTM)** capaz de prever os tempos de volta, um componente essencial para determinar a estrat√©gia de pneus mais eficaz para a corrida.

## üéØ Objetivo do Projeto

A estrat√©gia de pneus e a previs√£o de ritmo de corrida s√£o fatores cr√≠ticos para o sucesso na F√≥rmula 1. Este projeto busca responder √† seguinte pergunta:

> √â poss√≠vel, com base em dados hist√≥ricos de voltas, compostos de pneus, condi√ß√µes clim√°ticas e telemetria, treinar um modelo de s√©rie temporal para prever com acur√°cia o desempenho de um piloto em voltas futuras?

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3.x
* **Coleta de Dados:** [FastF1](https://theoehrly.github.io/Fast-F1/)
* **An√°lise e Manipula√ß√£o de Dados:** Pandas, NumPy
* **Machine Learning:** TensorFlow, Keras, Scikit-learn
* **Visualiza√ß√£o de Dados:** Matplotlib, Seaborn 
* **Ambiente:** Jupyter Notebook

## üìä Processo de Dados

A qualidade do modelo depende diretamente da qualidade dos dados. O processo foi dividido em quatro etapas principais:

### 1. Coleta de Dados via FastF1
Os dados foram coletados para o Grande Pr√™mio da It√°lia de 2018 a 2024. Um loop foi criado para buscar todas as sess√µes relevantes (Treinos Livres, Qualifica√ß√£o, Corrida e Sprint, quando aplic√°vel), tratando exce√ß√µes para anos ou sess√µes sem dados.

```python
import fastf1
import pandas as pd

# Listas para armazenar os objetos de sess√£o
sessions_monza_race = []
#...
weather_data = []

gp_name = 'Italian Grand Prix'

for year in range(2018, 2025):
    print(f"\n--- Processando ano: {year} ---")
    # L√≥gica para tratar o formato de Fim de Semana com Sprint (2021)
    if year == 2021:
        sessions_to_load = {'Race': ..., 'Sprint': ..., 'Qualifying': ...}
    else:
        sessions_to_load = {'Race': ..., 'Qualifying': ..., 'FP1': ..., 'FP2': ..., 'FP3': ...}

    for session_name, session_list in sessions_to_load.items():
        try:
            session = fastf1.get_session(year, gp_name, session_name)
            session.load() # Carrega os dados da sess√£o (incluindo telemetria)
            weather_data.append(session.weather_data)
            session_list.append(session)
            print(f"  -> Sucesso: '{session_name}' de {year} carregado.")
        except Exception as e:
            print(f"  -> Falha: N√£o foi poss√≠vel carregar '{session_name}' de {year}.")
```

### 2. Consolida√ß√£o e Jun√ß√£o de Dados
Ap√≥s a coleta, os dados de voltas (`laps`) e meteorol√≥gicos (`weather_data`) de todas as sess√µes e anos foram consolidados em dois DataFrames principais. Em seguida, foi utilizada a fun√ß√£o `pandas.merge_asof` para enriquecer os dados de cada volta com as informa√ß√µes meteorol√≥gicas mais pr√≥ximas no tempo.

```python
df_laps = pd.concat(all_laps, ignore_index=True)
df_weather = pd.concat(all_weather, ignore_index=True)

# Ordena por tempo para a jun√ß√£o
df_laps = df_laps.sort_values(by='LapStartTime').reset_index(drop=True)
df_weather = df_weather.sort_values(by='Time').reset_index(drop=True)

# Jun√ß√£o 'asof' para encontrar o dado de clima mais pr√≥ximo para cada volta
df_merged = pd.merge_asof(
    left=df_laps,
    right=df_weather,
    left_on='LapStartTime',
    right_on='Time',
    by='Year',
    direction='nearest'
)
```

### 3. Feature Engineering e Limpeza
Esta √© a etapa mais cr√≠tica. Novas features foram criadas e os dados foram limpos para garantir que apenas informa√ß√µes relevantes e precisas fossem usadas no modelo:
* **`FuelLoad`**: Uma estimativa da carga de combust√≠vel foi criada, assumindo um consumo de 1.6 kg por volta a partir de uma carga inicial de 110 kg.
* **Codifica√ß√£o Categ√≥rica**: `Compound` (composto do pneu) e `Driver` foram transformados em features num√©ricas usando One-Hot Encoding (`pd.get_dummies`).
* **Limpeza de Dados**:
    * Voltas sem `LapTime` foram removidas.
    * Apenas voltas marcadas como `IsAccurate == True` pelo FastF1 foram mantidas.
    * `LapTime` foi convertido para segundos (`LapTimeSeconds`) e outliers (tempos > 200s) foram descartados.
    * Dezenas de colunas irrelevantes ou com dados redundantes foram removidas para simplificar o modelo.

```python
# Feature Engineering: Carga de Combust√≠vel
df_merged['FuelLoad'] = 110 - (df_merged['LapNumber'] * 1.6)

# One-Hot Encoding
df_merged = pd.get_dummies(df_merged, columns=['Compound', 'Driver'], prefix=['Compound', 'Driver'])

# Limpeza e sele√ß√£o de voltas v√°lidas
df_clean = df_merged[df_merged['IsAccurate'] == True].copy()
df_clean['LapTimeSeconds'] = df_clean['LapTime'].dt.total_seconds()
df_clean.dropna(subset=['LapTimeSeconds'], inplace=True)
df_clean = df_clean[df_clean['LapTimeSeconds'] < 200]

# Remo√ß√£o de colunas desnecess√°rias
features_to_exclude = ['Time_x', 'LapStartTime', 'Team', 'Position', ...]
df_final = df_clean.drop(columns=features_to_exclude, errors='ignore')
```

### 4. Salvando o Dataset Processado
O DataFrame final, limpo e processado, foi salvo em um arquivo CSV para facilitar o reuso e a etapa de modelagem.
```python
df_final.to_csv('dados_monza_2018_2024.csv', index=False)
```

## üß† O Modelo LSTM

Um modelo LSTM (Long Short-Term Memory) foi escolhido por sua efic√°cia em aprender com dados sequenciais, como uma s√©rie temporal de voltas de corrida.

### 1. Prepara√ß√£o para S√©ries Temporais
* **Divis√£o Temporal**: Os dados foram divididos em treino (`anos < 2024`) e teste (`ano == 2024`), garantindo que o modelo seja testado em dados que ele nunca viu, simulando um cen√°rio de previs√£o real.
* **Normaliza√ß√£o**: Todas as features foram normalizadas entre 0 e 1 usando `MinMaxScaler` para otimizar o processo de treinamento da rede neural.
* **Cria√ß√£o de Sequ√™ncias**: Os dados foram transformados em sequ√™ncias. Para cada ponto, o modelo recebe uma sequ√™ncia de `10` voltas anteriores para prever o tempo da pr√≥xima volta. Esse processo √© feito ano a ano para n√£o misturar dados de GPs diferentes em uma mesma sequ√™ncia.

```python
from sklearn.preprocessing import MinMaxScaler

# Divis√£o temporal dos dados
cut_off_year = 2024
train_df = df_final[df_final['Year'] < cut_off_year]
test_df = df_final[df_final['Year'] == cut_off_year]

# Fun√ß√£o para criar sequ√™ncias de dados
def create_sequences(X_data, y_data, sequence_length=10):
    X_sequences, y_sequences = [], []
    for i in range(len(X_data) - sequence_length):
        X_sequences.append(X_data[i:(i + sequence_length)])
        y_sequences.append(y_data[i + sequence_length])
    return np.array(X_sequences), np.array(y_sequences)

# Normaliza√ß√£o e cria√ß√£o das sequ√™ncias para treino e teste
scaler = MinMaxScaler()
```

### 2. Arquitetura do Modelo
O modelo foi constru√≠do com a API Keras do TensorFlow, contendo duas camadas LSTM com regulariza√ß√£o `Dropout` para evitar overfitting e uma camada `Dense` de sa√≠da para a predi√ß√£o final.

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

sequence_length = X_train.shape[1]
n_features = X_train.shape[2]

model = Sequential(name="Modelo_F1_LSTM")
model.add(LSTM(units=128, activation='tanh', return_sequences=True, input_shape=(sequence_length, n_features)))
model.add(Dropout(0.2))
model.add(LSTM(units=64, activation='tanh'))
model.add(Dropout(0.2))
model.add(Dense(units=1, activation='linear')) # Ativa√ß√£o linear para regress√£o
```
**Sum√°rio do Modelo:**
```
Model: "Modelo_F1_LSTM"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 lstm (LSTM)                 (None, 10, 128)           ...
 dropout (Dropout)           (None, 10, 128)           0
 lstm_1 (LSTM)               (None, 64)                ...
 dropout_1 (Dropout)         (None, 64)                0
 dense (Dense)               (None, 1)                 65
=================================================================
Total params: ...
Trainable params: ...
Non-trainable params: 0
_________________________________________________________________
```

### 3. Compila√ß√£o e Treinamento
O modelo foi compilado com o otimizador `Adam` e a fun√ß√£o de perda `mean_squared_error`, adequada para problemas de regress√£o. Callbacks como `EarlyStopping` e `ReduceLROnPlateau` foram usados para um treinamento mais robusto e eficiente.

```python
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)
model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])

# Callbacks para otimizar o treino
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)

# Treinamento do modelo
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    shuffle=False, # Importante para s√©ries temporais
    callbacks=[early_stopping, reduce_lr]
)
```

## üìà Resultados

```python
# C√≥digo para gerar o gr√°fico de perda
import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='Perda no Treino')
plt.plot(history.history['val_loss'], label='Perda na Valida√ß√£o')
plt.title('Curva de Aprendizado do Modelo')
plt.xlabel('√âpocas')
plt.ylabel('Mean Squared Error')
plt.legend()
plt.show()
```

## üí° Pr√≥ximos Passos e Melhorias

* [ ] Expandir a an√°lise para outros circuitos para criar um modelo mais generalista.
* [ ] Testar outras arquiteturas de modelos (ex: GRU, Transformers for Time Series).
* [ ] Incorporar mais dados de telemetria (RPM, velocidade, acionamento de freio/acelerador).
* [ ] Construir uma interface simples com Streamlit ou Flask para fazer previs√µes interativas.

## ‚úíÔ∏è Autor

**[Kau√™ Santos]**

* [LinkedIn](https://www.linkedin.com/in/kau√™-santos-0a381b25a)
* [GitHub](https://github.com/KWSantos)
